<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" xml:lang="en" lang="en">

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
<meta name="description" content="homepage"/>
<meta name="keywords" content="homepage" />
<meta name="author" content="S. Singh" />
<link rel="stylesheet" type="text/css" href="style/style.css" media="screen" />
<title>Shashank Singh</title>
</head>

<body>

<!-- ------------------------  header  ------------------------ -->

<div id="header">
   <div class="center_wrapper">
      <div id="site_title">
      <br>
         <h1><a href="https://sss1.github.io/">Shashank Singh</a></h1>
      </div>
   </div>
</div>

<!-- ------------------------  navigation  ------------------------ -->

<div id="navigation">
    <div class="center_wrapper">
        <ul>
                <li class="current_page_item"><a href="index.html" title="About Shashank">Home</a></li>
                <li><a href="publications.html" title="Research Publications">Publications</a></li>
                <li><a href="code.html" title="Project Code">Code</a></li>
                <li><a href="CV.pdf" title="My CV (click for PDF)">Curriculum Vitae</a></li>
                <li><a href="courses.html" title="Courses I've taken">Courses</a></li>
                <li><a href="teaching.html" title="Courses I've helped teach">Teaching</a></li>
                <li><a href="links.html"
                    title="Some things I find interesting">Links</a></li>
        </ul>

        <div style="clear:both"></div>

        </div>
</div>

<!-- ------------------------  main body  ------------------------ -->

<div id="main_wrapper">
    <div class="center_wrapper">
      <div id="main">

    <br>

    <h3>Contact Information</h3>
    <div>
    <img style="float: right" src="images/me2.jpg" height="250" width="330" padding="20" title="I like climbing trees." alt="I like climbing trees.">
    Software Engineer, Google, Pittsburgh<br>
    <!-- <a href="http://www.stat.cmu.edu/">Department of Statistics</a> and<br>
    <a href="http://www.ml.cmu.edu/">Machine Learning Department</a><br>
    <br>
    Office:
    <a href="https://www.google.com/maps/place/Gates+Hillman+Complex/@40.4437252,-79.9466346,17z/data=!3m1!4b1!4m2!3m1!1s0x8834f22177d9f8ef:0x719357c7895d25a8">GHC</a> 8206<br>
    <a href="https://en.wikipedia.org/wiki/Carnegie_Mellon_University">Carnegie Mellon University</a><br>
    5000 Forbes Avenue<br>
    Pittsburgh, PA 15213<br>
    <br>-->
    
    Phone: (615) 364-7734<br>

    Email: shashankssingh44 [at] gmail [dot] com

    </div>
    <br>
    I'm a software engineer at Google (Pittsburgh). I recently finished a PhD
    in Machine Learning and Statistics at Carnegie Mellon University,
    advised by <a href="http://www.cs.cmu.edu/~bapoczos/">Barnabas Poczos</a>.
    <br>
    <br>
    My main research is in statistical machine learning - using
    statistical models to understand when and why machine learning algorithms
    work. I also develop models and tools (of math, stats, and machine learning
    varieties) to help researchers in biology and psychology analyze their data.
    <br>
    <br>
    Some specific things I've worked on, by topic:
    <br>
    <br>
      Statistical Machine Learning
        <ul>
          <li>Statistical guarantees (minimax bounds) for:
            <ul>
              <li>Generative Adversarial Networks (GANs) and other density estimators</li>
              <li>Estimating entropy/mutual information/divergence, smoothness, and other properties of probability distributions</li>
	            <li>Multi-class nearest-neighbor classification</li>
	            <li>Shallow unsupervised convolutional neural networks</li>
            </ul>
	        </li>
	      </ul>
      Applied Machine Learning
        <ul>
          <li>Forecasting the effects of the COVID-19 epidemic (at Google)</li>
          <li>Compressing and accelerating large deep neural networks (at Amazon)</li>
        </ul>
      Computational Biology
        <ul>
          <li>Deep learning to predict gene interactions from DNA sequence</li>
	        <li>Differential equations and multi-agent simulations to model bacterial swarm chemotaxis</li>
        </ul>
      Psychology
        <ul>
          <li>Probabilistic modeling and deep learning to analyze eye-tracking data and study sustained attention development in children</li>
        </ul>

    <!--Before that (2010-2014), I studied Computer Science and Math as an undergrad at CMU in 2014.-->
    <!--I'm fortunate to be supported
    by a <a href="https://www.nsfgrfp.org/">Graduate Research Fellowship</a>
    from the NSF and the Richard King Mellon Foundation Fellowship in the Life Sciences.
    In the summer of 2015, I interned at
    <a href="http://www.google.com/about/careers/locations/mountain-view/">
    Google (Mountain View)</a>, where I worked on a project using anomaly
    detection methods to detect user-engagement abuse.
    <br>
    <br>
    <h3>Research</h3>
    My broad research interests are in the mechanisms and limits of stochastic
    information processing in both artificial and biological systems, viewed
    through a rigorous mathematical lens. I am also passionate about most
    other parts of mathematics, statistics, and theoretical computer science,
    especially analysis, information theory, and algorithms/complexity, as
    well as more biological areas such as computational and systems
    biology, genomics, and cognitive development. Specific areas I have worked
    in include nonparametric statistics, generative adversarial modeling,
    sparse dictionary learning, and modeling and prediction in biological
    systems, including (neural) functional connectivity, bacterial swarms,
    higher-order genome organization.
    <br>
    <br>
    <h5>Some Current Projects</h5>
    <b>Nonparametric Density Functional Estimation</b><br>
    With <a href="http://www.cs.cmu.edu/~bapoczos/">Barnab&aacute;s
    P&oacute;czos</a>, I'm studying estimators for integral functionals of
    probability densities, including information theoretic quantities (e.g.,
    families of entropy, mutual information, divergence) and Sobolev norms.
    We first derived convergence rates for boundary corrected plug-in estimators
    of
    <a href="publications/papers/singh_renyi_div_ICML14.pdf">Renyi divergence</a>
    and
    <a href="publications/papers/singh_density_func_NIPS14.pdf">more general functionals</a>.
    We then derived the first convergence rates for popular but poorly
    understood K-nearest neighbor estimators of
    <a href="publications/papers/singh_KozaLeo_draft.pdf">entropy</a> and then
    <a href="publications/papers/singh_KNN_NIPS16.pdf">more general functionals</a>.
    Achieving optimal convergence rates with these estimators often requires
    knowledge of the smoothness of the densities in question, which is rarely
    available in practice. Recently, we studied estimation of
    <a href="publications/papers/singh_sobolev_NIPS16.pdf">Sobolev Norms</a>
    (a common measure of smoothness of a function), which may help us
    develop estimators that can adapt to densities of unknown smoothness.
    Most recently, we studied estimation of mutual information and entropy under
    a
    <a href="publications/papers/singh_nonparanormal_information_estimation.pdf">Gaussian copula assumption</a>.
    This somewhat restricts the interactions that
    can be modeled but often leads to significantly faster convergence in high
    dimensions. Even if the data are not truly from a Gaussian copula, this
    often gives a more useful result than a fully nonparametric estimator (which
    can fail to converge with realistic sample sizes), despite being
    asymptotically inconsistent.
    We are interested in deriving convergence rates and
    confidence intervals for these estimators, as well as applying these
    estimators, for example (with
    <a href="http://www.psy.cmu.edu/~coaxlab/">Timothy Verstynen</a>), to study
    connectivity of brain regions using fMRI data. This work is related to a
    <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1247658">
    large project </a> on generalizing machine learning algorithms and
    theory to high-dimensional distributional data and other data with complex
    explicit structure.
    <br>
    <br>
    <b>Bacterial Swarm Optimization</b><br>
    With <a href="http://www.cs.cmu.edu/~zivbj/">Ziv Bar-Joseph</a> and
    <a href="http://www.cs.cmu.edu/~saketn/">Saket Navlakha</a> I'm working on
    biologically inspired distributed algorithms; specifically, inspired by
    cooperative foraging behavior of E. coli swarms, we are studying a
    <a href="publications/papers/singh_bacterial_DGD_RECOMB_2016.pdf">
    distributed optimization framework</a> that provably converges under very
    general constraint and objective functions and strong constraints on
    communication. We're also trying to understand the communication networks
    and mechanisms used by real E. coli cells.
    <br>
    <br>
    <b>Deep Learning for Prediction from Gene Sequence Data</b><br>
    With <a href="http://www.cs.cmu.edu/~jianma/">Jian Ma</a>, I'm working on
    leveraging recent advances in deep learning to develop a system that uses
    only DNA sequence information to predict certain functional properties of
    genes. Historically, most prediction methods have relied on using epigenetic
    markers as predictors, due to difficulty extracting relevant features
    directly from the genetic code. We recently implemented a
    <a href="publications/papers/singh_SPEID_preprint.pdf">
    deep neural network model</a> that helps by automatically learning
    informative features of the genetic sequence. We also implemented a <a href = "publications/papers/yang_EPI_ISMB17.pdf">gradient-boosting model</a>, which it better able to explicitly predictive sequence features. These models may eventually reduce the
    need for gathering expensive and time-consuming experimental data, and help
    elucidate the mechanisms by which the DNA sequence determines its own
    function in different cell types.
    <br>
    <br>
    <h5>Some Past Projects</h5>
    <b>Computational Neuroscience of Vision</b><br> With
    <a href="http://www.cnbc.cmu.edu/~tai/">Tai Sing Lee</a> and
    <a href="http://www.cnbc.cmu.edu/~samondjm/">Jason Samonds</a>,
    I studied computational models of binocular disparity perception in visual
    systems of primates, with interest in modelling understanding how neural network
    dynamics encode perceptual uncertainty. I'm keen to revisit neural data
    analysis after developing well-understood tools for estimating
    information-theoretic quantities.
    <br>
    <br>
    <br>
    <br>
    <b>Margin-based Active Learning</b><br>
    With <a href="http://www.cs.cmu.edu/~ninamf/">Nina Balcan</a> I'm
    developing a margin-based algorithm for active learning.
    <a href = "http://www.cs.cmu.edu/~ninamf/papers/optimal-lin-sep.pdf">
    Previous work</a> showed under log-concave distributions, active learners
    can learn linear separators exponentially faster than passive learners. I'm
    generalizing this to broader class of separators and underlying
    probability distributions, and to allow certain feature noise, as well as
    trying to use ideas from this area as the basis for active learning on
    distributions.-->
    &nbsp;<br>
    &nbsp;<br>
    <br>
  </div>
</div>
</div>
    
<!-- ------------ footer ------------ -->

<div id="footer">
  <div class="left">
        &copy; 2020 Shashank Singh

    <p><!-- hhmts start -->
Last updated: July 25, 2020
<!-- hhmts end --></p>
   </div>
</div>
<!-- Start of Google Analytics Code -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54783645-1', 'auto');
    ga('send', 'pageview');

</script>
<!-- End of Google Analytics Code -->
</body>
</html>
